# Simulador Multi-Agente

Implementa√ß√£o de um simulador de sistemas multi-agente com Q-Learning para ambientes de navega√ß√£o e forrageamento.

## üìã Caracter√≠sticas

- **Q-Learning**: Implementa√ß√£o completa de aprendizagem por refor√ßo
- **Multi-agente**: Suporte para m√∫ltiplos agentes simult√¢neos
- **Dois ambientes**: Farol (navega√ß√£o) e Foraging (coleta de recursos)
- **CLI interativo**: Interface amig√°vel para configura√ß√£o e execu√ß√£o
- **An√°lise de resultados**: Gera√ß√£o autom√°tica de gr√°ficos e m√©tricas
- **Pol√≠ticas mistas**: Compara√ß√£o entre agentes com Q-Learning e pol√≠ticas fixas
- **Visualiza√ß√£o**: Representa√ß√£o gr√°fica dos ambientes e agentes

## üöÄ Requisitos

- Python 3.10+
- NumPy >= 1.21.0
- Matplotlib >= 3.5.0
- Questionary >= 2.0.0

### Instala√ß√£o

```bash
pip install -r requirements.txt
```

O script `run.sh` instala automaticamente as depend√™ncias se necess√°rio.

## üéÆ Como Executar

### CLI Interativo (Recomendado)

O simulador inclui uma interface interativa que guia o utilizador atrav√©s de todas as op√ß√µes:

```bash
./run.sh
```

O CLI permite configurar:
- **Ambiente:** FAROL ou FORAGING
- **Modo:** APRENDIZAGEM (treinar) ou TESTE (avaliar pol√≠tica treinada)
- **N√∫mero de agentes:** Quantidade total de agentes na simula√ß√£o
- **Distribui√ß√£o:** Quantos agentes usam Q-Learning vs pol√≠tica fixa
- **Epis√≥dios:** N√∫mero de epis√≥dios a executar
- **Max passos:** N√∫mero m√°ximo de passos por epis√≥dio
- **Gr√°ficos:** Selecionar quais gr√°ficos gerar no final

**Funcionalidades:**
- ‚úÖ Ativa automaticamente o ambiente virtual Python
- ‚úÖ Executa simula√ß√£o principal sem visualiza√ß√£o (mais r√°pido)
- ‚úÖ Mostra visualiza√ß√£o apenas no epis√≥dio final
- ‚úÖ Gera e abre automaticamente gr√°ficos de an√°lise
- ‚úÖ Guarda resultados em CSV
- ‚úÖ Suporta cancelamento com `Ctrl+C`

### Modo Manual (Legado)

```bash
# ambiente farol (default)
python -m sma.run farol

# ambiente foraging
python -m sma.run foraging

# com visualiza√ß√£o
python -m sma.run farol --visual

# especificar n√∫mero de epis√≥dios
python -m sma.run foraging -e 200

# guardar resultados
python -m sma.run farol -o resultados.csv
```

## üìÅ Estrutura do Projeto

```
sma/
  core/              # Classes base (agente, ambiente, simulador)
    - agente_base.py      # Classe abstrata de agente
    - ambiente_base.py    # Classe abstrata de ambiente
    - simulador.py        # Motor de simula√ß√£o
    - politicas.py        # Implementa√ß√£o de Q-Learning
    - sensores.py         # Sistema de sensores
    - visualizador.py     # Visualiza√ß√£o gr√°fica
    - resultados.py       # Gest√£o de m√©tricas
  agentes/           # Implementa√ß√µes dos agentes
    - agente_farol.py     # Agente para ambiente Farol
    - agente_forager.py   # Agente para ambiente Foraging
  ambientes/         # Implementa√ß√µes dos ambientes
    - farol.py            # Ambiente de navega√ß√£o ao farol
    - foraging.py         # Ambiente de forrageamento
  cli.py             # Interface interativa (CLI)
  comparar_politicas.py  # Compara√ß√£o de pol√≠ticas
  gerar_analise.py   # Gera√ß√£o de an√°lises e gr√°ficos
  config_*.json      # Ficheiros de configura√ß√£o
  resultados/        # Resultados exportados (CSV)
  analise/           # Gr√°ficos gerados (PNG)
  qtables/           # Q-tables guardadas (JSON)
run.sh               # Script para executar CLI
requirements.txt     # Depend√™ncias Python
```

## üåç Ambientes

### Farol
Agentes t√™m de navegar at√© ao farol usando Q-Learning. Recebem a dire√ß√£o relativa ao farol como observa√ß√£o atrav√©s de sensores. O objetivo √© alcan√ßar o farol no menor n√∫mero de passos poss√≠vel.

**Caracter√≠sticas:**
- Observa√ß√£o: Dire√ß√£o relativa ao farol
- A√ß√µes: Mover nas 4 dire√ß√µes (Norte, Sul, Este, Oeste)
- Recompensa: Positiva ao alcan√ßar o farol, negativa por passos sem progresso

### Foraging
Agentes recolhem recursos e depositam no ninho. Ambiente mais complexo que envolve coletar recursos e deposit√°-los no ninho.

**Caracter√≠sticas:**
- Observa√ß√£o: Estado do agente (com/sem recurso), posi√ß√£o relativa ao ninho e recursos
- A√ß√µes: Mover, coletar recursos, depositar no ninho
- Recompensa: Baseada no valor dos recursos depositados

## ‚öôÔ∏è Configura√ß√£o

### Via CLI Interativo

O CLI gera automaticamente a configura√ß√£o baseada nas escolhas do utilizador. N√£o √© necess√°rio editar ficheiros JSON manualmente.

### Via Ficheiros JSON (Modo Manual)

Os ficheiros `config_*.json` definem os par√¢metros da simula√ß√£o:
- `modo_execucao`: APRENDIZAGEM ou TESTE
- `episodios`: N√∫mero de epis√≥dios
- `max_passos`: Passos por epis√≥dio
- `visualizar`: true/false
- Par√¢metros do ambiente e agentes

## üìä An√°lise de Resultados

O simulador gera automaticamente:
- **Curvas de aprendizagem**: Evolu√ß√£o da recompensa ao longo dos epis√≥dios
- **M√©tricas de desempenho**: Taxa de sucesso, passos m√©dios, recompensas
- **Compara√ß√£o de pol√≠ticas**: Q-Learning vs pol√≠ticas fixas
- **Exporta√ß√£o CSV**: Dados brutos para an√°lise externa

Consulte `ANALISE_RESULTADOS.md` para mais detalhes sobre an√°lise de resultados.

## üìö Documenta√ß√£o Adicional

- `relatorio.md`: Relat√≥rio t√©cnico completo da arquitetura e implementa√ß√£o
- `CODE_REVIEW.md`: Revis√£o de c√≥digo e melhorias
- `ANALISE_RESULTADOS.md`: Guia de an√°lise de resultados
- `TESTES_REALIZADOS.md`: Documenta√ß√£o de testes realizados

## üîß Desenvolvimento

### Estrutura Modular

O projeto segue uma arquitetura modular:
- **Core**: Componentes base reutiliz√°veis
- **Agentes**: Implementa√ß√µes espec√≠ficas por ambiente
- **Ambientes**: Defini√ß√µes dos espa√ßos de simula√ß√£o
- **Pol√≠ticas**: Algoritmos de aprendizagem (Q-Learning)

### Extensibilidade

Para adicionar novos ambientes ou agentes:
1. Criar classe que herda de `Ambiente` ou `Agente`
2. Implementar m√©todos obrigat√≥rios
3. Adicionar configura√ß√£o JSON correspondente

## üìÑ Licen√ßa

Este √© um projeto desenvolvido para fins educacionais.
